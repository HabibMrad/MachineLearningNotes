\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{indentfirst}
\usepackage{mathtools}
\usepackage{setspace}
\setlength{\parindent}{2em}
\begin{document}
\title{Support Vector Machines}\author{jufan}\date{\today}
\maketitle
\tableofcontents

\section{Support Vector Machines}
Consider a linear classifier for a binary classification problem with labels \emph{\textbf{y}} and features \emph{\textbf{x}}. And we use $y\in \{-1,1\}$ to denote the class labels.

The classifier is written as :
\begin{equation*}
h_{w,b}(x)=g(w^Tx+b)
\end{equation*}
where $g(z)=1$ if $z\geq0$, and $g(z)=-1$ otherwise.

Given a training example $(x^{(i)},y^{(i)})$

Definition of \emph{\textbf{functional margin}}:
\begin{equation*}
\hat{\gamma}^{(i)}=y^{(i)}(w^Tx+b)
\end{equation*}
And a large functional margin represents a confident and a correct prediction.
For a training set $S\ =\ \{(x^{(i)},y^{(i)});i=1,\ldots,m\}$, we have the functional margin of $(w,b)$ with respect to $S$ to be the smallest functional margins of the individual training examples:
\begin{equation*}
\hat{\gamma}=\min_{i=1,\ldots,m}\hat{\gamma}^{(i)}
\end{equation*}

Problem of functional margin: by exploiting our freedom to scale \emph{\textbf{w}} and \emph{\textbf{b}}, we can make the functional margin arbitrarily large without really changing anything meaningful.

Definition of \emph{\textbf{geometric margins}}:
Consider a training example, which is a point with label $y^{(i)}=1$ at A, its distance to the decision boundary is $\gamma^{(i)}$ (the line segment AB). $w/\lVert w \rVert$ is a unit-length vector pointing in the same direction as \emph{w}, and point A represents $x^{(i)}$, so point B is given by $x^{(i)}-\gamma^{(i)}\cdot w/\lVert w \rVert$. Since B lies on the decision boundary, and points on the decision boundary satisfy the equation $w^T+b=0$, we have:
\begin{equation*}
w^T\left(x^{(i)}-\gamma^{(i)}\frac{w}{\lVert w \rVert}\right) + b =0
\end{equation*}
Solving for $\gamma^{(i)}$ yields
\begin{equation*}
\gamma^{(i)}=\frac{w^Tx^{(i)}+b}{\lVert w\rVert}={\left(\frac{w}{\lVert w\rVert}\right)}^Tx^{(i)}+\frac{b}{\lVert w\rVert}
\end{equation*}
So the \emph{\textbf{geometric margin}} of $(w,b)$ with respect to a $+1$ class training example $(x^{(i)},y^{(i)})$ is:
\begin{equation*}
\gamma^{(i)}=y^{(i)}\left(\left(\frac{w}{\lVert w\rVert}\right)^T x^{(i)}+\frac{b}{\lVert w\rVert}\right)
\end{equation*}
For a training set $S\ =\ \{(x^{(i)},y^{(i)});i=1,\ldots,m\}$, we have the geometric margin of $(w,b)$ with respect to $S$ to be the smallest geometric margins of the individual training examples:
\begin{equation*}
\gamma=\min_{i=1,\ldots,m}\gamma^{(i)}
\end{equation*}

Assume that we are given a training set that is \emph{\textbf{linearly separable}} (possible to separate the positive and negative examples using separating hyperplane).
We need to find the separating hyperplane with the maximum geometric margin, thus have the optimization problem:
\begin{align*}
\max\nolimits_{\gamma,w,b} \gamma \\
    \text{s.t.}\ &y^{(i)}(w^T x^{(i)}+b)\geq\gamma,\ i=1,\ldots,m \\
                  &\lVert w\rVert=1
\end{align*}

$\lVert w\rVert=1$ constraint is to ensure that the functional margin equals the geometric margin.

A cleaner version without the nasty (non-convex) constraint $\lVert w\rVert=1$:
\begin{align*}
\max\nolimits_{\gamma,w,b} \frac{\hat{\gamma}}{\lVert w\rVert} \\
    \text{s.t.}\ &y^{(i)}(w^Tx^{(i)}+b)\geq\hat{\gamma},\ i=1,\ldots,m
\end{align*}

We introduce the scaling constraint that the \emph{\textbf{functional margin}} of $w,b$ with respect to the training set must be 1:
\begin{equation*}
\hat{\gamma}=1
\end{equation*}
Thus we have the following optimization problem transformed from above:
\begin{align*}
\min\nolimits_{\gamma,w,b}\ &\ \frac{1}{2}\lVert w\rVert^2 \\
                  &\ \text{s.t.}\  y^{(i)}(w^Tx^{(i)}+b)\geq1,\ i=1,\ldots,m
\end{align*}

Now time to introduce \emph{\textbf{Lagrange duality}}.

Original problem:
\begin{align*}
\min\nolimits_w\ &\ f(w) \\
                 &\ \text{s.t.}\ h_i(w)=0,\ i=1,\ldots,l
\end{align*}
Define \emph{\textbf{Lagrangian}} to be:
\begin{equation*}
L(w,\beta)=f(w)+\sum_{i=1}^l\beta_ih_i(w)
\end{equation*}
Where the $\beta_i$'s are called \emph{\textbf{Lagrange multipliers}}.
We set $L$'s partial derivatives to zero and solve for $w$ and $\beta$:
\begin{equation*}
\frac{\partial L}{\partial w_i}=0;\ \frac{\partial L}{\partial \beta_i}=0
\end{equation*}

Now the formal part for \emph{\textbf{Lagrange Duality}}
Define the \emph{\textbf{primal optimization problem}}:
\begin{align*}
\min\nolimits_w\quad\quad &f(w) \\
\text{s.t.}\quad &g_i(w)\leq0,\quad i=1,\ldots,k \\
                 &h_i(w)=0,\quad i=1,\ldots,l
\end{align*}
Define the \emph{\textbf{generalized Lagrangian}}:
\begin{equation*}
L(w,\alpha,\beta)=f(w)+\sum_{i=1}^{k}\alpha_ig_i(w)+\sum_{i=1}^l\beta_ih_i(w)
\end{equation*}
where $\alpha_i$'s and $\beta_i$'s are \emph{\textbf{Lagrange multipliers}}
Consider the quantity:
\begin{equation*}
\theta_p(w)=\max_{\alpha,\beta:\alpha_i\geq0}L(w,\alpha,\beta)
\end{equation*}

If $w$ violates any of the primal constraints (e.g. if either $g_i(w)>0$ or $h_i(w)\neq0$ for some $i$), then we have:
\begin{align*}
\theta_p(w)\ &=\ \max_{\alpha,\beta:\alpha_i\geq0}f(w)+\sum_{i=1}^k\alpha_ig_i(w)+\sum_{i=1}^l\beta_ih_i(w) \\
             &=\ \infty
\end{align*}
Conversely if all constraints are satisfied for a particular value of $w$, then $\theta_p(w)=f(w)$.
So we have:
\begin{equation*}
\theta_p(w)=\begin{cases}
f(w)\quad &\text{if $w$ satisfies primal constraints} \\
\infty    &\text{otherwise}
\end{cases}
\end{equation*}


\end{document} 
