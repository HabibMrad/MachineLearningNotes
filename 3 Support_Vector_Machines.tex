\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{indentfirst}
\usepackage{mathtools}
\usepackage{setspace}
\setlength{\parindent}{2em}
\begin{document}
\title{Support Vector Machines}\author{jufan}\date{\today}
\maketitle
\tableofcontents

\section{Support Vector Machines}
Consider a linear classifier for a binary classification problem with labels \emph{\textbf{y}} and features \emph{\textbf{x}}. And we use $y\in \{-1,1\}$ to denote the class labels.

The classifier is written as :
\begin{equation*}
h_{w,b}(x)=g(w^Tx+b)
\end{equation*}
where $g(z)=1$ if $z\geq0$, and $g(z)=-1$ otherwise.

Given a training example $(x^{(i)},y^{(i)})$

Definition of \emph{\textbf{functional margin}}:
\begin{equation*}
\hat{\gamma}^{(i)}=y^{(i)}(w^Tx+b)
\end{equation*}
And a large functional margin represents a confident and a correct prediction.
For a training set $S\ =\ \{(x^{(i)},y^{(i)});i=1,\ldots,m\}$, we have the functional margin of $(w,b)$ with respect to $S$ to be the smallest functional margins of the individual training examples:
\begin{equation*}
\hat{\gamma}=\min_{i=1,\ldots,m}\hat{\gamma}^{(i)}
\end{equation*}

Problem of functional margin: by exploiting our freedom to scale \emph{\textbf{w}} and \emph{\textbf{b}}, we can make the functional margin arbitrarily large without really changing anything meaningful.

Definition of \emph{\textbf{geometric margins}}:
Consider a training example, which is a point with label $y^{(i)}=1$ at A, its distance to the decision boundary is $\gamma^{(i)}$ (the line segment AB). $w/\lVert w \rVert$ is a unit-length vector pointing in the same direction as \emph{w}, and point A represents $x^{(i)}$, so point B is given by $x^{(i)}-\gamma^{(i)}\cdot w/\lVert w \rVert$. Since B lies on the decision boundary, and points on the decision boundary satisfy the equation $w^T+b=0$, we have:
\begin{equation*}
w^T\left(x^{(i)}-\gamma^{(i)}\frac{w}{\lVert w \rVert}\right) + b =0
\end{equation*}
Solving for $\gamma^{(i)}$ yields
\begin{equation*}
\gamma^{(i)}=\frac{w^Tx^{(i)}+b}{\lVert w\rVert}={\left(\frac{w}{\lVert w\rVert}\right)}^Tx^{(i)}+\frac{b}{\lVert w\rVert}
\end{equation*}
So the \emph{\textbf{geometric margin}} of $(w,b)$ with respect to a $+1$ class training example $(x^{(i)},y^{(i)})$ is:
\begin{equation*}
\gamma^{(i)}=y^{(i)}\left(\left(\frac{w}{\lVert w\rVert}\right)^T x^{(i)}+\frac{b}{\lVert w\rVert}\right)
\end{equation*}
For a training set $S\ =\ \{(x^{(i)},y^{(i)});i=1,\ldots,m\}$, we have the geometric margin of $(w,b)$ with respect to $S$ to be the smallest geometric margins of the individual training examples:
\begin{equation*}
\gamma=\min_{i=1,\ldots,m}\gamma^{(i)}
\end{equation*}

Assume that we are given a training set that is \emph{\textbf{linearly separable}} (possible to separate the positive and negative examples using separating hyperplane).
We need to find the separating hyperplane with the maximum geometric margin, thus have the optimization problem:
\begin{align*}
\max\nolimits_{\gamma,w,b} \gamma \\
    \text{s.t.}\ &y^{(i)}(w^T x^{(i)}+b)\geq\gamma,\ i=1,\ldots,m \\
                  &\lVert w\rVert=1
\end{align*}

$\lVert w\rVert=1$ constraint is to ensure that the functional margin equals the geometric margin.

A cleaner version without the nasty (non-convex) constraint $\lVert w\rVert=1$:
\begin{align*}
\max\nolimits_{\gamma,w,b} \frac{\hat{\gamma}}{\lVert w\rVert} \\
    \text{s.t.}\ &y^{(i)}(w^Tx^{(i)}+b)\geq\hat{\gamma},\ i=1,\ldots,m
\end{align*}

We introduce the scaling constraint that the \emph{\textbf{functional margin}} of $w,b$ with respect to the training set must be 1:
\begin{equation*}
\hat{\gamma}=1
\end{equation*}
Thus we have the following optimization problem transformed from above:
\begin{align*}
\min\nolimits_{\gamma,w,b}\ &\ \frac{1}{2}\lVert w\rVert^2 \\
                  &\ \text{s.t.}\  y^{(i)}(w^Tx^{(i)}+b)\geq1,\ i=1,\ldots,m
\end{align*}

Now time to introduce \emph{\textbf{Lagrange duality}}.

Original problem:
\begin{align*}
\min\nolimits_w\ &\ f(w) \\
                 &\ \text{s.t.}\ h_i(w)=0,\ i=1,\ldots,l
\end{align*}
Define \emph{\textbf{Lagrangian}} to be:
\begin{equation*}
L(w,\beta)=f(w)+\sum_{i=1}^l\beta_ih_i(w)
\end{equation*}
Where the $\beta_i$'s are called \emph{\textbf{Lagrange multipliers}}.
We set $L$'s partial derivatives to zero and solve for $w$ and $\beta$:
\begin{equation*}
\frac{\partial L}{\partial w_i}=0;\ \frac{\partial L}{\partial \beta_i}=0
\end{equation*}

Now the formal part for \emph{\textbf{Lagrange Duality}}

Define the \emph{\textbf{primal optimization problem}}:
\begin{align*}
\min\nolimits_w\quad\quad &f(w) \\
\text{s.t.}\quad &g_i(w)\leq0,\quad i=1,\ldots,k \\
                 &h_i(w)=0,\quad i=1,\ldots,l
\end{align*}

Define the \emph{\textbf{generalized Lagrangian}}:
\begin{equation*}
L(w,\alpha,\beta)=f(w)+\sum_{i=1}^{k}\alpha_ig_i(w)+\sum_{i=1}^l\beta_ih_i(w)
\end{equation*}
where $\alpha_i$'s and $\beta_i$'s are \emph{\textbf{Lagrange multipliers}}
Consider the quantity:
\begin{equation*}
\theta_p(w)=\max_{\alpha,\beta:\alpha_i\geq0}L(w,\alpha,\beta)
\end{equation*}

If $w$ violates any of the primal constraints (e.g. if either $g_i(w)>0$ or $h_i(w)\neq0$ for some $i$), then we have:
\begin{align*}
\theta_p(w)\ &=\ \max_{\alpha,\beta:\alpha_i\geq0}\left(f(w)+\sum_{i=1}^k\alpha_ig_i(w)+\sum_{i=1}^l\beta_ih_i(w)\right) \\
             &=\ \infty
\end{align*}
Conversely if all constraints are satisfied for a particular value of $w$, then $\theta_p(w)=f(w)$.
So we have:
\begin{equation*}
\theta_p(w)=\begin{cases}
f(w)\quad &\text{if $w$ satisfies primal constraints} \\
\infty    &\text{otherwise}
\end{cases}
\end{equation*}
So now the minimization problem becomes:
\begin{equation*}
\min_w\theta_p(w)=\min_w\max_{\alpha,\beta:\alpha_i\geq0}L(w,\alpha,\beta)
\end{equation*}

Define:
\begin{equation*}
\theta_D(\alpha,\beta)=\min_wL(w,\alpha,\beta)
\end{equation*}
where "D" means "dual", and the \emph{\textbf{dual}} optimization problem is:
\begin{equation*}
\max_{\alpha,\beta:\alpha_i\geq0}\theta_D(\alpha,\beta)=\max_{\alpha,\beta:\alpha_i\geq0}\min_wL(w,\alpha,\beta)
\end{equation*}

So we have the relationship between optimal values of the two problems:
\begin{equation*}
d^\star=\max_{\alpha,\beta:\alpha_i\geq0}\min_wL(w,\alpha,\beta)\leq \min_w\max_{\alpha,\beta:\alpha_i\geq0}L(w,\alpha,\beta)=p^\star
\end{equation*}

Under certain conditions we have $d^\star=p^\star$. 
Conditions are: $f$ and the $g_i$'s are \emph{convex}, and the $h_i$'s are \emph{affine}, $g_i$'s are strictly feasible (there exists some $w$ so that $g_i(w)<0$ for all $i$)
Under the 3 assumptions above, we can find $w^\star,\alpha^\star,\beta^\star$ that $w_\star$ and $\alpha^\star,\beta^\star$ are solutions to the primal and dual problems respectively, and $p^\star=d^\star=L(w^\star,\alpha^\star,\beta^\star)$, also, $w^\star,\alpha^\star,\beta^\star$ satisfy the \emph{\textbf{Karush-Kuhn-Tucker(KKT) conditions}}:
\begin{align*}
\frac{\partial}{\partial w_i}L(w^\star,\alpha^\star,\beta^\star)\ &=\ 0,\ i=1,\ldots,n \\
\frac{\partial}{\partial \beta_i}L(w^\star,\alpha^\star,\beta^\star)\ &=\ 0,\ i=1,\ldots,l \\
\alpha_i^\star g_i(w^\star)\ &=\ 0,\ i=1,\ldots,k \\
g_i(w^\star)\ &\leq\ 0,\ i=1,\ldots,k \\
\alpha^\star\ &\geq\ 0,\ i=1,\ldots,k
\end{align*}
Conversely, if some $w^\star,\alpha^\star,\beta^\star$ satisfy the \emph{\textbf{KKT}} conditions, then they are also a solution to the primal and dual problems.

\emph{\textbf{attributes}} of a problem: the "original" input value

\emph{\textbf{features}} of a problem: the set of quantities that are mapped to and passed to the learning algorithm. The mapping process from attributes to features is called \emph{\textbf{feature mapping}}, represented by $\phi$.

For a certain feature mapping $\phi$, define \emph{\textbf{Kernel}} to be:
\begin{equation*}
K(x,z)=\phi(x)^T\phi(z)
\end{equation*}
Then we replace all the $\langle x,z\rangle$ in algorithm with $K(x,z)$, since the kernel may be very inexpensive to calculate, even though $\phi(x)$ itself may be very expensive to calculate (could be extremely high dimensional vector).

Define \emph{\textbf{primal problem with regularization}} as:
\begin{align*}
\min\nolimits_{\gamma,w,b}\quad &\quad\frac{1}{2}\lVert w\rVert^2+C\sum_{i=1}^m\varepsilon_i \\
      \text{s.t.}\quad &\quad y^{(i)}(w^Tx^{(i)}+b)\geq1-\varepsilon_i,\ i=1,\ldots,m \\
                       &\quad\varepsilon_i\geq0,\ i=1,\ldots,m
\end{align*}
Now examples are permitted to have \emph{functional margins} less than 1, and if an example has functional $1-\varepsilon_i\ (\varepsilon_i>0)$, we would pay a cost of the objective function being increased by $C\varepsilon_i$.
We can do the same dual problem trick as before.


\emph{\textbf{the SMO algorithm}}
read the book later.

\end{document} 
